<html>
 <head>
   <title>Madrona Projects</title>
     <link rel="icon" type="image/x-icon" href="favicon.ico">
     <meta name='viewport' content='width=device-width'>
     <link href='https://fonts.googleapis.com/css?family=JetBrains+Mono' rel='stylesheet'>
     <link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
     <link rel='stylesheet' href='style.css'>
 </head>
 <body id='projects-body'>
    <div class='madrona-nav-wrapper'>
      <div class='madrona-nav'>
        <a href='#' class='logo-wrapper'>
          <img src='madrona_simple.png' width='50'>
          <span class='logo'>Madrona&nbsp;Engine</span>
        </a>
        <div class='madrona-nav-items'>
          <a href='#paper' class='link'>
            Paper
          </a>
          <a href='#faq' class='link'>
            FAQ 
          </a>
          <a href='blog.html' class='link'>
            Blog
          </a>
          <a href='https://github.com/shacklettbp/madrona' class='gh'>
            <img src='github-mark.svg' alt='GitHub'>
          </a>
        </div>
      </div>
    </div>
   <section id='intro' class='info-section'>
     <div class='content'>
       <h2>Madrona: A GPU-Accelerated Game Engine for Training AI Agents</h2>
       <p class='detail blurb'>
         Training AI agents to perform challenging tasks often requires agents to make hundreds of millions to billions of trial-and-error actions in complex simulated learning environments. To enable rapid prototyping for machine learning research, these learning environments are often built on top of game engines like Unity or Unreal Engine that provide extensive off-the-shelf functionality and features. Unfortunately, these existing engines are not designed for the challenging computational workload of generating huge amounts of training experience, resulting in simulation costs bottlenecking end-to-end training experiments.
       </p>
       <p class='detail blurb'>
          To overcome these simulation bottlenecks, researchers have begun reimplementing learning environments from scratch using GPU-accelerated batch simulation. Batch simulators execute thousands of learning environments simultaneously on a single GPU, enabling orders of magnitude end-to-end speedups to training experiments. The challenge is that building these batch simulators requires low-level GPU programming expertise and extensive engineering effort, resulting in relatively few batch simulators being built and used in research.
       </p>
       <p class='detail blurb'>
          To make building high-performance learning environments more accessible, we began the Madrona project. Inspired by the ease of use of game engines and the performance of batch simulators, the Madrona Engine aims to combine the best of both worlds into a game engine designed from the ground up for building high-performance, GPU-accelerated batch learning environments. Using just a single GPU, environments built on Madrona are capable of generating millions of simulated steps per second, often accelerating end-to-end experiments by orders of magnitude. The result has been several successful research projects using the engine since we presented it at SIGGRAPH 2023. These projects are described below, along with discussion of how each of them benefited from the performance and features of Madrona.
       </p>
     </div>
   </section>
   <section id='gpudrive' class='info-section'>
     <div class='content'>
      <h2>GPUDrive: Multi-Agent Driving Simulation at 1 Million FPS</h2>
      <div id='gpudrive-videos'>
        <img src='sim_video_7.gif'>
        <img src='obs_video_7.gif'>
      </div>
      <div id='gpudrive-caption'>
        <p>GPUDrive simulates a simplified driving environment so agents can focus on learning planning and coordination. Madrona allows GPUDrive to simulate thousands of independent driving scenarios simultaneously on a single GPU.</p>
      </div>
      <p class='detail blurb'>
      <a href='https://openreview.net/forum?id=ERv8ptegFi'>GPUDrive</a> is a high-level self driving car simulator that trains driving agents in scenarios from the <a href='https://waymo.com/open/'>Waymo Open Dataset</a>. Developed at NYU, GPUDrive is designed to accelerate reinforcement learning research on multi-agent planning for autonomous driving; a challenging and data-hungry learning task. Madrona's GPU acceleration enables GPUDrive to generate over a million steps of experience per second on a single GPU. The result is that an agent trained with GPUDrive can solve a scene from the Waymo dataset in seconds, rather than hours per scene for a purely <a href='https://openreview.net/forum?id=DcfsR89KUa'>CPU-based simulator</a> written by the GPUDrive authors previously.
      </p>
      <div id='waymax-vs-gpudrive'>
        <p class='detail blurb'>
        Additionally, key features of Madrona enable GPUDrive to significantly outperform <a href='https://waymo.com/research/waymax/'>Waymax</a>, a GPU-accelerated self driving simulator developed by Waymo, targetting the same dataset as GPUDrive. Waymax is built on <a href='https://docs.jax.dev/en/latest/'>JAX</a>, an array-based programming framework that accelerates bulk array operations on the GPU (or TPU). The key limitation of JAX is that programs must be written in terms of operations on statically sized arrays. The irregular nature of scenes in the Waymo dataset, where the number of active and parked vehicles and complexity of road geometry varies wildly, presents a challenge for the statically-sized array model enforced by JAX. As a result, Waymax must overallocate arrays for worst-case scene complexity, significantly limiting the amount of parallel work that can be mapped onto a single GPU. As shown on the right, due to this overallocation Waymax runs out of memory when simulating more than 16 parallel driving scenarios.
        </p>
        <img id='waymax-vs-gpudrive-img' src='waymax_vs_gpudrive.svg'>
     </div>
     <p class='detail blurb'>
     One of the core design goals of Madrona is to avoid the worst-case overallocation issues seen in Waymax (and other simulators built on array-based programming frameworks). Madrona supports high-performance dynamic allocation of GPU memory on a per-environment basis, allowing the number of simulated entities (cars, road segments, etc) to vary between driving scenarios without incurring memory overheads. This capability allows GPUDrive to simulate thousands of parallel driving scenarios simultaneously to achieve over 10 times higher throughput than Waymax.
     </p>
   </section>
   <section id='renderer' class='info-section'>
     <div class='content'>
      <h2>High-Performance 3D Rendering for Embodied AI</h2>
      <div id='renderer-videos'>
         <video autoplay muted playsinline loop height='300' poster='sim2real_shaking_thumbnail.jpg'>
           <source src='sim2real_shaking.mp4' type='video/mp4' />
         </video>
         <video autoplay muted playsinline loop height='300' poster='sim2real_sim_thumbnail.jpg'>
           <source src='sim2real_sim.mp4' type='video/mp4' />
         </video>
         <video autoplay muted playsinline loop height='300' poster='sim2real_franka_thumbnail.jpg'>
           <source src='sim2real_franka.mp4' type='video/mp4' />
         </video>
      </div>
      <div id='renderer-caption'>
        <p>Madrona's batch renderer combined with <a href='https://mujoco.readthedocs.io/en/stable/mjx.html'>Mujoco MJX physics</a> has already enabled sim2real transfer to robots at the University of Toronto performing simple push block and picking tasks.</p>
      </div>
      <p class='detail blurb'>
      Training agents to perform tasks using visual observations of the world is an important problem for robotics and embodied AI. These "pixels-to-actions" tasks are challenging, because agents must both learn the core control skills for their task while also processing complex incoming visuals to reason about the current state of their environment. End-to-end pixels-to-actions experiments often require billions of rendered images in total; as as result, the relatively slow renderers used in much of the prior work become a significant bottleneck to end-to-end experiment times.
 To accelerate research in this area, Madrona includes a high-performance <a href='https://madrona-engine.github.io/renderer.html'>3D "batch renderer"</a> that can render thousands of agent observations simultaneously for use with high-performance batch simulators that can reach millions of frames per second.
      </p>
      <div id='hssd-inset'>
        <p class='detail blurb'>
        Madrona's batch renderer is designed from the ground up to focus on throughput by exposing as much parallel rendering work to the GPU as possible. The renderer achieves hundreds of thousands of frames per second of aggregate throughput on simple environments and tens of thousands in complex environments such as the batch of agent views from the <a href='https://3dlg-hcvc.github.io/hssd/'>Habitat Synthetic Scenes Dataset</a> shown on the right.<br/>
        <br id='hssd-inset-linebreak'/>
        Additionally, the renderer utilizes high-performance Madrona APIs for exchanging simulator state on the GPU to provide a <i>simulator agnostic</i> interface to the renderer. A collaboration with researchers at Google Deepmind and the University of Toronto <a href='https://github.com/shacklettbp/madrona_mjx'>combined the Madrona renderer with Mujoco MJX</a> to provide support for high-performance pixels to actions training to <a href='https://playground.mujoco.org/'>Mujoco Playground</a>, an end-to-end platform for robot learning.
        </p>
        <img id='hssd' src='hssd.png'>
      </div>
      <p class='detail blurb'>
      A key Madrona feature that is reflected in the batch renderer's design as well is support for per-environment domain randomization: different numbers of objects in each environment, different textures and material properties for each object in each environment, and randomized lighting as well. These domain randomization features leverage the idea that in Madrona each environment can share as much, or as little, structure as is appropriate. Researchers at the University of Toronto have used the domain randomization features provided by the renderer to successfully transfer of policies learned in simulation to real-world robots using camera-based observations. These experiments are shown in the videos at the beginning of this section; note that the resulting policies are also robust to humans interfering with the robot.
      </p>

      <!-- Previously, researchers would be bottlenecked on the rendering of all these images. However, with our carefully designed renderer, we are able to comfortably achieve 10s of thousands of FPS for high complexity scenes and hundreds of thousands for simpler scenes (like the one you see for the "push block" task). We have made the renderer easy to integrate with <a href=''>non-Madrona simulators such as MJX</a> (used in the Sim2Real transfer shown above) so that researchers can make use of this performance regardless of the physics engine they use.

      <p class='detail blurb'>
        We call this renderer a "batch renderer" because it renders thousands of images all at once at as high throughput as possible. This means that our design was guided purely by throughput-maximization, and not latency-minimization (which you might want for a video game). We are able to leverage Madrona's core ECS systems and memory management schemes to enable the implementation of two different renderers: one based on rasterization and one based on ray tracing. Experiments have led us to converge towards the conclusion that ray tracing is the way forward with regard to embodied AI training. This is because ray tracing is an algorithm which makes more complex effects like shadows, lensing, global illumination much more approachable than rasterization.
      </p>
      -->
     </div>
   </section>
   <section id='physics' class='info-section'>
     <div class='content'>
      <h2>High-Performance, Realistic, and Customizable Rigid Body Physics in Madrona</h2>
      <!--<div id='competitive-videos'>
         <video autoplay muted playsinline loop height='300' poster='simple_map_replay_thumbnail.jpg'>
           <source src='simple_map_replay.mp4' type='video/mp4' />
         </video>
         <img src='competitive_big_map.jpg' height='300'>
      </div>-->
      <div id='competitive-caption'>
        <p>TODO</p>
      </div>
      <p class='detail blurb'>
      </p>
      <p class='detail blurb'>
      </p>
      <p class='detail blurb'>
      </p>
     </div>
   </section>
   <section id='competitive' class='info-section'>
     <div class='content'>
      <h2>Competitive Self Play in Large-Scale 3D Video Game Environments</h2>
      <div id='competitive-videos'>
         <video autoplay muted playsinline loop height='300' poster='simple_map_replay_thumbnail.jpg'>
           <source src='simple_map_replay.mp4' type='video/mp4' />
         </video>
         <img src='competitive_big_map.jpg' height='300'>
      </div>
      <div id='competitive-caption'>
        <p>Agents compete in a 6 vs 6 match to control regions of large 3D game maps. Agents must learn to navigate the map, control their weapons (aiming, shooting) and coordinate with their teammates.</p>
      </div>
      <p class='detail blurb'>
      Training agents to perform competitive tasks is inherently challenging, because the exact nature of the task (effective strategies, difficulty, etc) depends on the skill level of the agents' opponents. One popular technique to tackle these kinds of problems is self-play reinforcement learning, where the agent competes against copies of itself and continually improves. Self play has been used for flagship reinforcement learning results to produce super-human level agents in complex games like <a href='https://openai.com/index/openai-five-defeats-dota-2-world-champions/'>Dota 2</a> and <a href='https://deepmind.google/research/breakthroughs/alphago/'>Go</a>. 
      </p>
      <p class='detail blurb'>
      Although the promise of discovering previously unknown skills and strategies through self play is enticing, the computational costs of self play reinforcement learning on non-trivial environments have historically been far beyond the capabilities of most research labs. <a href='https://github.com/shacklettbp/madrona-mp-env'>MadronaShowdown</a> aims to solve this problem by providing a high performance, but also mechanically complex benchmark environment for self play reinforcement learning research. MadronaShowdown is a 6 vs 6 multiplayer game with mechanics inspired by games such as Call of Duty and Quake, where agents compete against eachother to control 3D game levels, including real game assets taken from <a href='https://github.com/Activision/madrona-mp-geo'>Activision's Caldera dataset</a>.
      </p>
      <p class='detail blurb'>
      MadronaShowdown relies on several of the core capabilities of the Madrona Engine. First, one of the key goals for Madrona is to provide high-performance APIs that allow for rapid "scripting" of task-specific logic that Madrona automatically schedules efficiently onto the GPU. MadronaShowdown uses these APIs extensively to implement custom game play logic for the environment: tracking player health, weapon states and game scoring to name a few; all this custom logic executes in parallel on the GPU alongside core engine routines. Second, MadronaShowdown leverages the thousands of parallel environments Madrona supports to train multiple deep neural networks (DNN) simultaneously on a single GPU. This allows the DNNs to learn different skills and strategies and compete with eachother, increasing the diversity of agent behaviors and stabilizing training.
      </p>
     </div>
   </section>
   <section id='overcooked' class='info-section'>
     <div class='content'>
       <h2>Learning Robust Human-Compatible Cooperative Strategies in Overcooked AI</h2>
      <p class='detail blurb'>
      TODO
      </p>
     </div>
   </section>
 </body>
</html>
