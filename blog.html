<!DOCTYPE html>
<html lang='en'>
  <head>
    <title>Madrona Engine</title>
    <meta charset='UTF-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1'>
    <link href='https://fonts.googleapis.com/css?family=JetBrains+Mono' rel='stylesheet'>
    <link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
    <link rel='stylesheet' href='style.css'>
  </head>

  <body>
    <div class='madrona-nav-wrapper'>
      <div class='madrona-nav'>
        <a href='#'>
          <img src='madrona_simple.png' width='50' />
          <span class='logo'>Madrona&nbsp;Engine</span>
        </a>
        <div class='madrona-nav-items'>
          <a href='#paper' class='link'>
            Paper
          </a>
          <a href='#faq' class='link'>
            FAQ 
          </a>
          <!-- <a href='#' class='link'>
            Blog
          </a> -->
          <a href='https://github.com/shacklettbp/madrona' class='gh'>
            <img src='github-mark.svg' alt='GitHub' />
          </a>
        </div>
      </div>
    </div>
    
    <div class='blog'>
      <div id='title' class='title'>
        <div class='title-bg'>
          <h1>Building a Game Engine for Training Agents on the GPU</h1>
          <p>Posted on Sunday, August 6th by <a href='https://cs.stanford.edu/~bps'>Brennan Shacklett</a></p>
        </div>
      </div>
      <section id='intro'>
        <p>
        About a year ago, I became interested in the following question: <strong>What would a game engine designed from the ground up for training agents look like?</strong>
        </p>
      </section>

      <section id='problem'>
        <h2>The Problem:</h2>
        <p>
        For context, training agents in virtual environments with algorithms like reinforcement learning requires huge amounts of experience: agents must take hundreds of millions or <a href='https://wijmans.xyz/publication/ddppo-2019/'>even billions</a> of simulated steps to learn complex tasks. Generating all this experience is a challenging workload: imagine a standard game engine designed to run at 60 or even 120 frames per second. Generating a billion steps sequentially would take almost 100 days of real-world time to train agents, not even counting the time needing for learning!
        </p>

        <p>
        Clearly, we need to run multiple game / simulator instances simultaneously to generate experience quickly enough to make training agents practical. One solution to this problem is simply use massive distributed compute, but a more efficient solution is to create <em>batch simulators</em> that can simulate agents across thousands of environments in parallel within a single simulator. This centralized management of data and execution makes it possible to map the parallel simulation workload to the GPU and achieve orders of magnitude speedups for end-to-end training! Examples include <a href="https://developer.nvidia.com/isaac-gym">NVIDIA's Isaac Gym</a> for robotics as well as the <a href="https://graphics.stanford.edu/projects/bps3D">BPS3D project</a> on rendering many environments simultaneously. 
        </p>

        <p>
        The problem with existing batch simulators is that they are purpose-built solutions for a specific family of tasks. This means when a machine learning researcher wants to start work on an interesting new task, they're left with a tough choice: implement a new batch simulator for the task, or accept orders of magnitude slower training times using an existing non-batch simulator. I've experienced the challenges arising from this personally: while working on improving rendering techniques for training agents, we were interested in adding scripted behaviors to the environment such as turning on and off lights or opening and closing curtains, but the fixed-function batch simulator we had built for simple navigation tasks didn't have an easy or maintable way to add this kind of one-off functionality.
        </p>

        <p>
        This state of affairs is a far cry from game development, where engines like Unity or Unreal provide extensive functionality for adding custom logic and state, and gluing together existing subsystems to make creating full fledged games significantly easier and faster than starting from scratch. For training agents, the question becomes the following: can we build a "batch" version of a game engine that allows users to relatively easily build batch simulators for new tasks while maintaining the high-performance GPU execution of purpose-built batch simulators?
       </p>
       <p>
       The answer to this question is non-obvious. Writing a batch simulator typically requires a lot of low-level parallel programming knowledge, as well as specific domain knowledge about the task at hand (how agents will interact with the environment, what information do the agents need, etc). Additionally, many game engines providing interfaces for scripting custom behaviors that don't seem like a good fit for GPU execution due to incoherent execution or lack of data locality. Would too much performance need to be sacrificed by a "batch" game engine to make it useful?
        </p>
      </section>

      <section id='ecs'>
        <h2>Entity Component System (ECS) On the GPU</h2>
        <p>
        While thinking about these questions and reading about existing game engine architectures, the Entity Component System (ECS) paradigm caught my attention. In an ECS, the game state (components) and game logic (systems) are cleanly separated. 
        </p>

      </section>
    </div>
  </body>
</html>
