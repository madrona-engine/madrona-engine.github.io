<!DOCTYPE html>
<html lang='en'>
  <head>
    <title>Madrona Engine</title>
    <meta charset='UTF-8'>
    <link rel='icon' type='image/x-icon' href='favicon.ico'>
    <meta name='viewport' content='width=device-width'>
    <link href='https://fonts.googleapis.com/css?family=JetBrains+Mono' rel='stylesheet'>
    <link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet'>
    <link rel='stylesheet' href='style.css'>
  </head>

  <body>
    <div class='madrona-nav-wrapper'>
      <div class='madrona-nav'>
        <a href='#' class='logo-wrapper'>
          <img src='madrona_simple.png' width='50'>
          <span class='logo'>Madrona&nbsp;Engine</span>
        </a>
        <div class='madrona-nav-items'>
          <a href='#paper' class='link'>
            Paper
          </a>
          <a href='#faq' class='link'>
            FAQ 
          </a>
          <a href='/blog.html' class='link'>
            Blog
          </a>
          <a href='https://github.com/shacklettbp/madrona' class='gh'>
            <img src='github-mark.svg' alt='GitHub'>
          </a>
        </div>
      </div>
    </div>

    <section id='video'>
      <div id='main-video-container'>
        <video autoplay muted playsinline width='720' height='405' poster='thumbnail.jpg'>
          <source src='zoomout.mp4' type='video/mp4' />
        </video>
        <button class='replay'><img src='replay.svg' alt='replay'></button>
      </div>
    </section>

    <section id='intro' class='info-section'>
      <div class='content'>
        <p class='detail blurb'>
        Madrona is a research game engine designed specifically for creating learning environments that execute with extremely
        high throughput on a single GPU (up to millions of aggregate environment steps per second). It achieves this by running thousands of independent instances of an environment concurrently on the GPU. Madrona's goal is to enable orders of magnitude speedups for AI agent training (and other
        applications needing large amounts of simulated experience) by making it easier for researchers to create new
        high-performance environments for a wide range of tasks.
        </p>
        <p class='detail blurb'>
        For more information, please see the following resources:
        <ul class='resources-list'>
          <li><a href='https://github.com/shacklettbp/madrona'>Madrona GitHub repo</a> (go here for a list of environments built using Madrona)</li>
          <li><a href='/blog.html'>Our short blog post introducing the engine</a></li>
          <li><a href='https://bsarkar321.github.io/blog/overcooked_madrona/index.html'>Bidipta Sarkar's post on building an Overcooked-AI batch simulator using Madrona</a></li>
          <li><a href='#paper'>SIGGRAPH 2023 paper</a> about the Madrona engine</li>
          <li><a href="#faq">Madrona FAQ</a></li>
        </li>

        </p>
      </div>
    </section>

    <section id='paper' class='info-section'>
      <h1>Technical Paper</h1>
      <div class='content'>
        <p class='detail'>
           Please refer to our technical paper for an in-depth description of core Madrona engine implementation details and for an analysis of the engine's performance.
        </p>

        <div class='paper-block'>
          <div class='paper-title-wrapper'>
            <a class='paper-title' href='shacklett_siggraph23.pdf' target='_blank'>
                An Extensible, Data-Oriented Architecture for High-Performance, Many-World Simulation
            </a>
          </div>
          <div class='paper-details-wrapper'>
            <div id='paper-details' class='paper-details'>
              <div class='authors'>
                <a href='https://cs.stanford.edu/~bps'>Brennan&nbsp;Shacklett</a>,
                <a href='https://www.linkedin.com/in/luc-rosenzweig/'>Luc&nbsp;Guy Rosenzweig</a>,
                <a href='https://zhiqiangxie.com/'>Zhiqiang&nbsp;Xie</a>,
                <a
                  href='https://scholar.google.com/citations?user=wr9RgmcAAAAJ&hl=en'>Bidipta&nbsp;Sarkar</a>,
                <a href='https://www.andrewszot.com/'>Andrew&nbsp;Szot</a>,
                <a href='https://wijmans.xyz/'>Erik&nbsp;Wijmans</a>,
                <a href='http://vladlen.info/'>Vladlen&nbsp;Koltun</a>,
                <a href='https://faculty.cc.gatech.edu/~dbatra/'>Dhruv&nbsp;Batra</a>,
                <a href='http://graphics.stanford.edu/~kayvonf/'>Kayvon&nbsp;Fatahalian</a>
              </div>
              <div class='conference'>
                Transactions on Graphics 2023 (Presented at SIGGRAPH 2023)
              </div>
            </div>
            <div id='paper-download'>
              <a href='shacklett_siggraph23.pdf' target='_blank'>
                <span class='pdf-download-icon material-symbols-outlined'>description</span><div class='pdf-download-text'>PDF</div>
              </a>
            </div>
          </div>
        </div>

        <h3>Abstract</h3>
        <p class='detail paper-abstract'>
        Training AI agents to perform complex tasks in simulated worlds requires millions to billions of steps of experience. To achieve high performance, today's fastest simulators for training AI agents adopt the idea of batch simulation: using a single simulation engine to simultaneously step many environments in parallel. We introduce a framework for productively authoring novel training environments (including custom logic for environment generation, environment time stepping, and generating agent observations and rewards) that execute as high-performance, GPU-accelerated batched simulators. Our key observation is that the Entity Component System (ECS) design pattern, popular for expressing CPU-side game logic today, is also well-suited for providing the structure needed for high-performance batched simulators. We contribute the first fully-GPU accelerated ECS implementation that natively supports batch environment simulation. We demonstrate how ECS abstractions impose structure on a training environment's logic and state  that allows the system to efficiently manage state, amortize work, and identify GPU-friendly coherent parallel computations within and across different environments. We implement several learning environments in this framework, and demonstrate GPU speedups of two to three orders of magnitude over open source CPU baselines and 5x &mdash; 33x over strong baselines running on a 32-thread CPU.  An implementation of the OpenAI hide and seek 3D environment written in our framework, which performs rigid body physics and ray tracing in each simulator step, achieves over 1.9&nbsp;million environment steps per second on a single GPU.
        </p>

        <h3>Citation</h3>
        <pre class='citation'><code>@article{shacklett23madrona,
    title   = {An Extensible, Data-Oriented Architecture for
               High-Performance, Many-World Simulation},
    author  = {Brennan Shacklett and Luc Guy Rosenzweig and
               Zhiqiang Xie and Bidipta Sarkar and Andrew Szot and
               Erik Wijmans and Vladlen Koltun and Dhruv Batra and 
               Kayvon Fatahalian},
    journal = {ACM Trans. Graph.},
    volume  = {42},
    number  = {4},
    year    = {2023}
}</code></pre>
      </div>
    </section>

    <section id='faq' class='info-section'>
      <h1>FAQ</h1>
      <div class='content'>

        <h3>What's the best way to contact Madrona's developers?</h3>

        <p class='detail'>
        Please contact us by opening a <a href='https://github.com/shacklettbp/madrona/issues'>GitHub issue</a> or directly reaching out via email to the first author of the <a href="shacklett_siggraph23.pdf">SIGGRAPH 2023 Madrona publication</a>.
        </p>


        <h3>What environments / tasks does Madrona support?</h3>
        
        <p class='detail'>
        Madrona is not an RL environment simulator. It is a game engine / framework that makes it easier for developers (like RL researchers) to create their own environment simulators that achieve high throughput by running on GPUs. For example, instead of creating a new environment simulator using an existing game engine like Unity or Unreal, you might consider creating it using Madrona to achieve higher experience generation speed.
        </p>
        <p class='detail'">We try to maintain an updated list of environment simulators built with Madrona on the <a href='https://github.com/shacklettbp/madrona#example-madrona-based-simulators'>Madrona GitHub README</a>. If you've made your own environment using Madrona and want to share, let us know and we'll add it to the list.
        </p>

        <h3>My learning task requires simulation of complex dynamical systems in contact-rich settings. (I currently use MuJoCo or IsaacGym.) Is Madrona a good fit for my work?</h3>

        <p class="detail">
          At the moment, probably not. Madrona currently provides a XPBD-based rigid body physics library for basic 3D collision and contact support. However, tasks that require advanced physics implementations (such as robotics manipulation tasks) are likely better off using other systems at this time. Hopefully in the future we can find ways to integrate libraries like <a href="https://mujoco.org/">MuJoCo</a> or <a href="https://developer.nvidia.com/isaac-gym">Isaac Gym</a> into Madrona by allowing them to communicate with the rest of the game engine using ECS structures. This would enable the development of new environments that are unconstrained in their custom game logic and also benefit from world-class physics simulation.
        </p>

        <h3>Does Madrona have rendering support? Can I use Madrona for training "pixels to actions" agents?</h3>

        <p class='detail'>
        Madrona currently has rendering support for visualization purposes only. While Madrona can simulate thousands of environments concurrently, the visualizer can only view a single environment at a time, and this output isn't exposed to PyTorch. Adding high-performance batch rendering support using ideas from our prior <a href='https://graphics.stanford.edu/projects/bps3D/'>bps3D project</a> is something we hope to do in the near future. Let us know if you have an immediate use case for it. The learning tasks we used as initial drivers of Madrona development involved agent policies that took internal game state to actions, so fast rendering has been lower priority for us.
        </p>


        <h3>I have an existing environment simulator written in Python. What is the easiest way to port it to Madrona?</h3>

        <p class='detail'>
        At this time Madrona requires game logic to be written in C++, so using Madrona will require porting this logic to C++ and re-organizing your game state to leverage the entity component system architecture. Bidipta Sarkar has a <a href='https://bsarkar321.github.io/blog/overcooked_madrona/index.html'>great post</a> on porting the <a href="https://github.com/HumanCompatibleAI/overcooked_ai">Overcooked-AI</a> environment to Madrona. That post describes the process of extracting the core simulation logic from a large Python code base and re-implementing it using Madrona's C++ APIs. A trivial port of Overcooked-AI was done in only a few days, and increased Overcooked-AI simulator performance by over 1000X.  The Madrona <a href="https://github.com/shacklettbp/madrona">github repo</a> also contains links to sample projects that can be used as starter code for creating new environments.

        <h3>Can I use Madrona while keeping parts of my simulator (e.g., reward functions) in Python?</h3>

        <p class='detail'>
        Yes. While Madrona currently requires the core custom environment simulation logic for a task to be written in C++, logic that executes at the end of the simulation step like reward functions can be implemented using PyTorch tensor operations. This is possible by exporting any of the internal simulation state (ECS components) needed as input to the reward functions as PyTorch tensors, and then computing rewards in PyTorch after Madrona finishes the current step. Madrona provides built-in support for exporting ECS components to PyTorch, making this relatively straightforward.
        </p>

        <h3>How is Madrona related to projects like NVIDIA Warp or Numba?</h3>
        
        <p class='detail'>
        Projects like <a href="https://github.com/NVIDIA/warp">NVIDIA Warp</a> and <a href="https://numba.pydata.org/">Numba</a> (and others) aim to make GPU programming easier by bringing high-level languages (Python) to the GPU. These frameworks could provide a high-productivity way to author individual ECS systems for use within the Madrona engine. A useful future project would be to engineer the appropriate support for generating Madrona-compatible CUDA kernels from ECS systems written in these languages. (Contact us if you're interested in contributing!)
        </p>

        <p class="detail">Doing so would allow developers to build complex batch simulators while realizing the productivity benefits of expressing environment logic in high-level languages and the performance benefits of using ECS APIs for efficiently managing state (custom components, creating and deleting entities) and gluing together different systems.
        </p>
        
        <h3>Can I use Madrona with a different learning framework than PyTorch?</h3>

        <p class='detail'>
        Madrona exports simulation state to learning frameworks using <a href='https://github.com/wjakob/nanobind'>nanobind</a>'s dlpack integration that supports most common frameworks. Currently, only PyTorch entry points for this functionality are exposed, because that is the framework we use and test. If you're interested in using Madrona with a different learning framework, please open a <a href='https://github.com/shacklettbp/madrona/issues'>GitHub issue</a> with a link to training code in your preferred framework for testing purposes and we can add the core engine support.
        </p>

      </div>
    </section>

    <p></p>

    <script src='main.js'></script>
  </body>
</html>
